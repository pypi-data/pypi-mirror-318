batch_sizes : [1, 16, 32, 64, 128]
nr_of_epochs : [200]
model_sizes : [8, 16, 32, 64, 128, 256, 512, 1024] # TODO 1024 did not work on rackham, test this by itself? Or use in combination with a smaller batch-size?
learning_rates : [0.03, 0.003, 0.0003]
regularize : [True, False]
dropout_rates : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]
weight_constraints : [1.0, 2.0, 3.0, 4.0, 5.0]