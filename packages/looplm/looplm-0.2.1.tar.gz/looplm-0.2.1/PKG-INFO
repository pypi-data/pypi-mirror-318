Metadata-Version: 2.1
Name: looplm
Version: 0.2.1
Summary: Loop-LM: Tool to access LLMs from the command line
Author: Chaitanya Devaguptapu
Author-email: tdchaitanya@gmail.com
Requires-Python: >=3.10,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: boto3 (>=1.35.57,<2.0.0)
Requires-Dist: click (>=8.1.7,<9.0.0)
Requires-Dist: cryptography (>=43.0.3,<44.0.0)
Requires-Dist: litellm (>=1.52.3,<2.0.0)
Requires-Dist: prompt-toolkit (>=3.0.48,<4.0.0)
Requires-Dist: rich (>=13.9.4,<14.0.0)
Requires-Dist: textual (>=0.89.0,<0.90.0)
Description-Content-Type: text/markdown

<div align="center">

# LoopLM

ü§ñ A powerful tool for seamlessly integrating LLMs in your development workflow

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Documentation](https://img.shields.io/badge/docs-mkdocs-blue)](https://chaitanya.one/looplm)

</div>

---

> [!NOTE]
> LoopLM is in active development. While fully functional, expect frequent updates and improvements.

LoopLM is a highly customisable command line tool that seamlessly integrates various Language Models into your development workflow. It offers a unified, secure, and efficient way to interact with state-of-the-art AI models directly from your terminal.

## Features

- üöÄ **Support for multiple LLM providers**: Works with OpenAI, Anthropic, Google Gemini, Azure OpenAI, AWS Bedrock, and other providers through [LiteLLM](https://litellm.vercel.app/docs/providers) integration. You can easily switch between different providers and models
- üîí **Secure Configuration**: All API keys and credentials are stored securely using encryption
- üíª **Simple CLI**: Intuitive command-line interface for quick access to LLMs and pipe support for integration with Unix tools
- üí¨ **Interactive Chat Mode**: Engage in persistent, interactive conversations with your preferred LLM using looplm chat
- üîç **Rich Output**: Beautiful terminal output with markdown support

## Quick Start

1. Install LoopLM ([pipx](https://github.com/pypa/pipx) is recommended):
```bash
pipx install looplm
```

2. Configure your first provider:
```bash
looplm --configure
```

3. Start using the CLI:
```bash
looplm "Write a function to calculate fibonacci numbers in Python"
```

## Why LoopLM?

LoopLM is designed for developers who:
- Want quick access to LLMs without leaving the terminal
- Work with multiple LLM providers and need a unified interface
- Want to integrate LLM assistance into their development workflow

## Requirements

- Python 3.10 or higher
- API keys for the providers you want to use

## üìñ Documentation

For comprehensive documentation, visit [our documentation site](https://chaitanya.one/looplm).
