# real-llama-cpp-python
A simple custom wrapper for llama.cpp models in Python, support seamlessly interaction with LangChain.

## Background
Installing llama-cpp-python is a pain in the bum. However, langchain only supports llama-cpp-python. I had a long Xmas leave and couldn't install the latest llama-cpp-python to run the quantized models from the latest llama.cpp. I decided to create my own version of real-llama-cpp-python to be:wq compatible with LangChain. 

## Installation

```bash
pip install custom-llm
