Metadata-Version: 2.1
Name: openrelik-ai-common
Version: 0.4.0
Summary: Common utilities for OpenRelik AI functionality
Author: Johan Berggren
Author-email: jberggren@gmail.com
Requires-Python: >=3.12,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: backoff (>=2.2.1,<3.0.0)
Requires-Dist: google-cloud-aiplatform (>=1.70.0,<2.0.0)
Requires-Dist: google-generativeai (>=0.8.3,<0.9.0)
Requires-Dist: ollama (>=0.3.3,<0.4.0)
Requires-Dist: ratelimit (>=2.2.1,<3.0.0)
Description-Content-Type: text/markdown

### Common utilities for OpenRelik AI functionality.

```python
# LLM providers are configured via environment variables
# export OLLAMA_SERVER_URL=http://localhost:11434
# export OLLAMA_DEFAULT_MODEL=gemma2:9b

from openrelik_ai_common.providers import manager

provider = manager.LLMManager().get_provider("ollama")
llm = provider(model_name="gemma2:9b", system_instructions="Your name is Foobar.")

# Single text generation
response = llm.generate(prompt="Hello, what is your name?")
print(response)

# Multiturn chat session
response = llm.chat("What is your name?")
print(response)
response = llm.chat("My name is John Doe")
print(response)
response = llm.chat("What is my name?")
print(response)

# Chat on the command line
while True:
    message = input("Message: ")
    response = llm.chat(message)
    print(response)
```

##### Obligatory Fine Print
This is not an official Google product (experimental or otherwise), it is just code that happens to be owned by Google.

